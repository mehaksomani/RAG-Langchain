{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c99a793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5114833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"OPENAI_API_KEY is not set in the environment variables\")\n",
    "else:\n",
    "    print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf6e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "model.invoke(\"hello\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05147b04",
   "metadata": {},
   "source": [
    "output = hello How can I assist you today?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can provide more settings\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5, max_tokens=1000, top_p=0.95, frequency_penalty=0, presence_penalty=0)\n",
    "\n",
    "llm.invoke(\"what is the capital of the united states?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1874c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(template=\"Translate the following text to French: {input}\")\n",
    "# or prompt = PromptTemplate.from_template(\"Translate the following text to French: {input}\")\n",
    "\n",
    "chain = prompt | llm # this is a chain of the prompt and the model\n",
    "\n",
    "chain.invoke({\"input\": \"I love programming.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96cb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# adding a system prompt. A system prompt is used to set the behavior of the model.\n",
    "# messages = [\n",
    "#     (\"system\", \"You are a helpful assistant that answers questions about the United States. If you are asked about ANYTHING that is not related to the United States, you must say 'I cannot answer that question.'\"),\n",
    "#     (\"user\", \"What is your favorite color?\"),\n",
    "# ]\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that answers questions about the United States. If you are asked about ANYTHING that is not related to the United States, you must say 'I cannot answer that question.'\"),\n",
    "    HumanMessage(content=\"What is your favorite color?\"),\n",
    "]\n",
    "\n",
    "ai_message = model.invoke(messages)\n",
    "\n",
    "print(ai_message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdb440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    SystemMessage(content=\"You are a helpful assistant that answers questions about the United States. If you are asked about ANYTHING that is not related to the United States, you must say 'I cannot answer that question.'\"),\n",
    "    HumanMessage(content=\"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"input\": \"What is the capital of the United States?\"}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a9b59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a {occupation} named {name}. Get into character and pretend to be this role. Answer questions accordingly.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "])\n",
    "# another way to do it\n",
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a {occupation} named {name}. Get into character and pretend to be this role. Answer questions accordingly.\"),\n",
    "#     (\"user\", \"{input}\")\n",
    "# ])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\n",
    "    \"occupation\": \"old wizard\",\n",
    "    \"name\": \"Lord Jaquarious\",\n",
    "    \"input\": \"Hi!\"\n",
    "}).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a960267",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", \"You are a helpful assistant that answers questions. ONLY use the context provided to answer questions. If the context does not provide the answer, say 'I don't know.' Context: {context}\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"context\": \"The capital of Germany is Berlin.\", \"input\": \"What is the capital of the United States?\"}).content\n",
    "chain.invoke({\"context\": \"The capital of Germany is Berlin.\", \"input\": \"What is the capital of Germany?\"}).content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
